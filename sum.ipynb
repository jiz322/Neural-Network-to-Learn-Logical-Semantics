{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28672"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ALCIR-data-parsesupervise.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "with open(\"ALCIR-data-parsesupervise-10k.txt\") as file2:\n",
    "    lines2 = file2.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line_index in range(len(lines)):\n",
    "    lines[line_index] = lines[line_index].split(\"\\t\")\n",
    "    lines[line_index].pop(2)\n",
    "    \n",
    "for line_index in range(len(lines2)):\n",
    "    lines2[line_index] = lines2[line_index].split(\"\\t\")\n",
    "    lines2[line_index].pop(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_len:  8000\n",
      "count:  4005\n"
     ]
    }
   ],
   "source": [
    "# Training set and Testing set splited here.\n",
    "\n",
    "lenth = len(lines2)\n",
    "import random\n",
    "random.seed(10)\n",
    "random.shuffle(lines2)\n",
    "train_list = lines2[0:int(lenth*0.8)]\n",
    "test_list = lines2[int(lenth*0.8):]\n",
    "\n",
    "lenth = len(lines)\n",
    "train_list_short = lines[0:int(lenth*0.8)]\n",
    "test_list_short = lines[int(lenth*0.8):]\n",
    "\n",
    "print(\"train_len: \", len(train_list))\n",
    "count = 0\n",
    "for i in train_list:\n",
    "    if i[0] == \"satisfiable\":\n",
    "        count += 1\n",
    "    \n",
    "print(\"count: \", count)\n",
    "\n",
    "    \n",
    "\n",
    "# print(\"train_len: \", len(train_list))\n",
    "# # count = 0\n",
    "# # for i in train_list:\n",
    "# #     if i[0] == \"satisfiable\":\n",
    "# #         count += 1\n",
    "    \n",
    "# # print(\"count: \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import BatchSampler, Sampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED=4321\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class Corpora():\n",
    "    \"\"\"\n",
    "    The class holds training and test corpora.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        # word to index (1-based integers) mapping\n",
    "        self.word_index = {\"N0O0N\":0}\n",
    "        # list of reviews tuples, each of which is (sentence_list, rate),\n",
    "        self.training_reviews = []\n",
    "        # (sentence_list, rate) Same format as training_sentences\n",
    "        self.test_reviews = []\n",
    "\n",
    "        self.max_len = 0\n",
    "\n",
    "\n",
    "    # input: a tuple (reviewList, rate)\n",
    "    # todo: insert values into fields\n",
    "    # Return the list representing all index of words in a review.\n",
    "    def insert_fields(self, input):   \n",
    "        # Sentence list\n",
    "        word_indexes = []\n",
    "        for word in input:\n",
    "            if word not in self.word_index.keys():\n",
    "                self.word_index.update({word:len(self.word_index.keys())}) #No add 1 because 0 is already in\n",
    "            # find the index of this word, add to return list\n",
    "            word_indexes.append(self.word_index[word])\n",
    "        if len(word_indexes)>self.max_len:\n",
    "            self.max_len = len(word_indexes)\n",
    "        return word_indexes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Different than P2, here we \n",
    "    def read_corpus(self, is_training):\n",
    "        if is_training is True:\n",
    "            target = train_list\n",
    "        else:\n",
    "            target = test_list\n",
    "        print(\"reading corpus ...\")\n",
    "        for rate, text in tqdm(target):\n",
    "            if rate == \"satisfiable\":\n",
    "                rate = 1.0\n",
    "            if rate == \"unsatisfiable\":\n",
    "                rate = 0.0\n",
    "            input = text.split(\" \")\n",
    "            tuple = (self.insert_fields(input), rate)\n",
    "            if is_training: \n",
    "                self.training_reviews.append(tuple)\n",
    "            else:\n",
    "                self.test_reviews.append(tuple)\n",
    "                    \n",
    "                \n",
    "# Inherient Dataset, convert list and int to tensors, load to GPU.\n",
    "class ReviewRateDataset(Dataset):\n",
    "   \n",
    "    def __init__(self, review_rate_pairs): # NB: sequence_pairs is corpora.training_reviews, \n",
    "        # list of (sentence_list, rate)\n",
    "        self.review_rate_pairs = review_rate_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review_rate_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence_list, rate = self.review_rate_pairs[idx] \n",
    "        return torch.tensor(sentence_list), torch.tensor(int(rate))\n",
    "\n",
    "# NB! This class will be in DataLoader function as a parameter for batch_sampler\n",
    "class SortedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "        Each sequence in a mini-batch must of the same lengths, while our sentences\n",
    "        are of various lengths.\n",
    "        We can pad the sentences to the same lengths in each mini-batch.\n",
    "        But if a short and long sentences are in the same mini-batch, more paddings\n",
    "        are needed.\n",
    "        We sort the sentences based on their lengths (in descending order)\n",
    "            and then put sentences with similar lengths in a batch to reduce the paddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \"\"\"\n",
    "            dataset: an torch.utils.data.DataSet object containing all training sequences\n",
    "            batch_size: the number of sequences to put in a mini-batch\n",
    "        \"\"\"\n",
    "\n",
    "        # The sorting and batching go within this function.      \n",
    "        self.batch_size = batch_size \n",
    "        # Sort the dataset (Based on the length of sentence.)\n",
    "        dataset.review_rate_pairs  = sorted(dataset.review_rate_pairs,key=lambda x:len(x[0]), reverse=True)\n",
    "        self.sorted_lengths = len(dataset)\n",
    "        # Batching: Split the dataset into a list of datasets\n",
    "        self.index_batches = []  \n",
    "        # -- NB: Collate function does not work, so I pad it directly.\n",
    "        for i in range(self.__len__()):\n",
    "            self.index_batches.append(padding_collate_func(ReviewRateDataset(dataset.review_rate_pairs[i*batch_size:i*batch_size+batch_size])))\n",
    "        # Now, each mini-batches is a ReviewRateDataset object\n",
    "        # If else format is needed, may change it latter.\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "            return a Python iterator object that iterates the mini-batchs of\n",
    "                training data indices (not individual indices)\n",
    "        \"\"\"\n",
    "        return iter(self.index_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sorted_lengths // self.batch_size\n",
    "\n",
    "# NB! This function will be in DataLoader function as a parameter for collate_fn\n",
    "def padding_collate_func(batch):\n",
    "    \"\"\"\n",
    "        Transform pairs of input-output sequences in the batch to be of the same length using the function\n",
    "            torch.nn.utils.rnn.pad_sequence.\n",
    "        batch: An iterator and each element is a pair of (input_sequence, output_sequence).\n",
    "        For POS tagging, len(input_sequence) = len(output_sequence). But for different\n",
    "        pairs in batch, their lengths can differ.\n",
    "\n",
    "        Example: a batch of 3 pairs of input/output sequences\n",
    "                [([1,2,3],[1,1,1]), ([1,2,3,4],[2,2,2,2]), ([1,2,3,4,5],[3,3,3,3,3])]\n",
    "                Note: [] encloses tensors (not numpy arra ys)\n",
    "                \n",
    "                \n",
    "                !!!!!NB QUESTION:  it is the inner [] that encloses tensors, right?\n",
    "                Comment: Batch is an element of a Sampler (see test_p1.py, a l[0] is a batch)\n",
    "                \n",
    "                \n",
    "        return: two tensors (one for input sequence batch and another for output sequence batch).\n",
    "                These tensors are padded with zeros so that all sequences in the same batch\n",
    "                are of the same length.\n",
    "        Example: input_sequence_batch = [[1,2,3,0,0], [1,2,3,4,0], [1,2,3,4,5]],\n",
    "                 output_sequence_batch = [[1,1,1,0,0], [2,2,2,2,0], [3,3,3,3,3]]\n",
    "\n",
    "    \"\"\"\n",
    "    ### Your codes go here (5 points) ###\n",
    "    # Hint: read the article linked at the top of this cell.\n",
    "    \n",
    "    # NOTe\n",
    "    # len(batch[0][0]) == len(batch.sequence_pairs[0]) == the target value (the maximum length for each batch)\n",
    "    # I fill it might be easier to pad sequence_pairs with tuple (0,0), but let's see.\n",
    "    \n",
    "    # Doubles the memory takes by this batch, which is not good\n",
    "    new_l = []\n",
    "    rate = []\n",
    "    for i,j in batch.review_rate_pairs:\n",
    "        new_l.append( torch.tensor(i))\n",
    "        rate.append( torch.tensor(int(j)))\n",
    "    padded = pad_sequence(new_l, batch_first=True, padding_value=0)\n",
    "    #print(\"len \", len(padded), len(rate)) #BUG: NEED ZIP HERE\n",
    "    obj = ReviewRateDataset(list(zip(padded,rate)))\n",
    "    # NB: For now the outter [] is neither tensor nor list, it is an obj!\n",
    "    # Change latter if necessary\n",
    "    # Yes, let's change it to two tensors return\n",
    "    ret1 = []\n",
    "    ret2 = []\n",
    "    for i in obj:\n",
    "        ret1.append(i[0])\n",
    "        ret2.append(i[1])\n",
    "    ret1 = torch.stack(ret1)\n",
    "    ret2 = torch.stack(ret2)\n",
    "    return ret1, ret2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:00<00:00, 65358.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading corpus ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 86502.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences = 8000\n",
      "Number of test sentences = 2000\n",
      "Number of unique input tokens = 10\n",
      "Maximal sentence length = 133\n",
      "\n",
      "\n",
      " Creating training Dataset, Sampler, and Iterators...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Creating test Dataset, Sampler, and Iterators\n",
      "Training first batch max length = 133\n",
      "Training second batch max length = 133\n",
      "Training last batch max length = 1\n",
      "Training second last batch max length = 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "\n",
    "corpora = Corpora()\n",
    "\n",
    "corpora.read_corpus(True)\n",
    "corpora.read_corpus(False)\n",
    "\n",
    "print(f'Number of training sentences = {len(corpora.training_reviews)}')\n",
    "print(f'Number of test sentences = {len(corpora.test_reviews)}')\n",
    "print(f'Number of unique input tokens = {len(corpora.word_index)}')\n",
    "print(f'Maximal sentence length = {corpora.max_len}')\n",
    "\n",
    "print(\"\\n\\n Creating training Dataset, Sampler, and Iterators...\")\n",
    "training_dataset = ReviewRateDataset(corpora.training_reviews)\n",
    "training_sampler = SortedBatchSampler(training_dataset, batch_size=BATCH_SIZE)\n",
    "training_iterator = DataLoader(training_dataset,\n",
    "                                  collate_fn = padding_collate_func,\n",
    "                                  batch_sampler = training_sampler)\n",
    "print(\"\\n\\n Creating test Dataset, Sampler, and Iterators\")\n",
    "test_dataset = ReviewRateDataset(corpora.test_reviews)\n",
    "test_sampler = SortedBatchSampler(test_dataset, batch_size=BATCH_SIZE)\n",
    "test_iterator = DataLoader(test_dataset,\n",
    "                              collate_fn = padding_collate_func,\n",
    "                              batch_sampler = test_sampler)\n",
    "\n",
    "print(f'Training first batch max length = {len(list(training_sampler)[0][0][0])}')\n",
    "print(f'Training second batch max length = {len(list(training_sampler)[1][0][0])}')\n",
    "print(f'Training last batch max length = {len(list(training_sampler)[-1][0][0])}')\n",
    "print(f'Training second last batch max length = {len(list(training_sampler)[-2][0][0])}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Nueral Network Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import embedding, nn\n",
    "# There is really nothing to be stored in this object.\n",
    "# -- But wait, how about self.rnn and self.fc?\n",
    "# -- NB: NOW, I assume that the nn keep weights from the inherentance,\n",
    "# -- And these functions as Sum and FC will use these weight correctly\n",
    "class SumScoreAssigner(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, emb_dim, hid_dim, n_layers, dropout, bidirectional):\n",
    "        \"\"\"\n",
    "        :param input_dim: size of the vocabulary (number of unique tokens)\n",
    "        :param output_dim: number of unique POS tags \n",
    "        :param emb_dim: embedding dimensionality of each token\n",
    "        :param hid_dim: number of hidden neurons of a hidden state/cell\n",
    "        :param n_layers: number of RNN layers (2 for faster training)\n",
    "        :param dropout: dropout rate between 0 and 1at the embedding layer and rnn\n",
    "        :param bidirectional: 1 if use bidirectional and 0 if don't\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.fc0 = nn.Linear(emb_dim, emb_dim)\n",
    "        self.fc = nn.Linear(emb_dim, 2)\n",
    "           \n",
    "\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # -- COMMENT\n",
    "    # -- The src means sourse, which is a 2d array batch_size by sentence_len, it is a big 2d tensor\n",
    "    # -- NBBBBB: How to turn the POSTaggedDataset into a big 2d tensor see test_p2 line 4-7\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "\n",
    "        :param src: a [batch_size, sentence_len] array.\n",
    "                     Each row is a sequence of word indices and each column represents a position in the sequence.\n",
    "        :return: the predicted logits at each position. \n",
    "        \"\"\"\n",
    "\n",
    "        emb = self.embedding(src)\n",
    "        l1 = self.dropout(torch.tanh(self.fc0(emb)))\n",
    "        summ = torch.sum(l1, dim=1)\n",
    "        d = self.fc(summ)\n",
    "        return torch.softmax(d, dim=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(corpora.word_index)\n",
    "OUTPUT_DIM = 4\n",
    "EMB_DIM = 70\n",
    "HID_DIM = 4\n",
    "N_LAYERS = 1 # number of Sum layers.\n",
    "BIDIRECT = 0 # 0: single direction (the default setting); 1: bidirectional\n",
    "DROPOUT = 0.5\n",
    "# initialize the model\n",
    "ScoreAssigner = SumScoreAssigner(INPUT_DIM, OUTPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT, BIDIRECT).cpu()\n",
    "\n",
    "\n",
    "\n",
    "# Glove Embedding here?\n",
    "def init_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.0001, 0.0001)\n",
    "\n",
    "ScoreAssigner.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(ScoreAssigner.parameters())\n",
    "\n",
    "# we use 0 to represent padded POS tags and the loss function should ignore that.\n",
    "# we calculate the sum of losses of pairs in each batch\n",
    "PAD_INDEX = 0\n",
    "\n",
    "\n",
    "# input: vector of [length, output_dim], integer (score)\n",
    "# criterion = nn.CrossEntropyLoss(reduction = 'sum', ignore_index = PAD_INDEX)\n",
    "\n",
    "# DO NOT IGNORE!!\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
    "\n",
    "\n",
    "\n",
    "N_EPOCHS = 100\n",
    "CLIP = 1\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "training_losses = []\n",
    "test_losses = []\n",
    "\n",
    "\n",
    "\n",
    "#criterion = torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -- The Iterator is a Dataloader object. \n",
    "# -- Use for loop in iterator.batch_sampler to access each batches\n",
    "# -- In this case, each batches is having length 128\n",
    "\n",
    "# -- Need to Figure out: The way to compute loss for RNN\n",
    "num_epochs_train = 0\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    global num_epochs_train\n",
    "    model.train()\n",
    "    \n",
    "    tmp = optimizer.state_dict()\n",
    "    tmp[\"param_groups\"][0][\"lr\"] = 0.000001/(num_epochs_train+1)\n",
    "    optimizer.load_state_dict(tmp)\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    num_batchs = 0\n",
    "    total = 0\n",
    "\n",
    "    # batch[0]: the word batch\n",
    "    # batch[1]: the tag batch (target)\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "        z = ScoreAssigner.forward(batch[0].cpu())\n",
    "        #a = torch.softmax(z,dim=-1)\n",
    "        loss = 0\n",
    "\n",
    "        # cross entropy loss of softmax and score\n",
    "        #loss=criterion(d,(batch[1]).cpu())/BATCH_SIZE\n",
    "        loss = criterion(z, batch[1].cpu())\n",
    "        #print(z, batch[1], loss)\n",
    "        loss.backward()\n",
    "        # Clips gradient norm of an iterable of parameters.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "\n",
    "    return epoch_loss /total\n",
    "\n",
    "confusion_matrix = []\n",
    "num_epochs = 0\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    confusion_matrix.append(torch.zeros(2,2))\n",
    "    global num_epochs\n",
    "    for i, batch in tqdm(enumerate(iterator.batch_sampler)):\n",
    "        z = ScoreAssigner.forward(batch[0].cpu())\n",
    "        #print(z)\n",
    "        loss = 0\n",
    "        # softmax of logit\n",
    "        # cross entropy loss of softmax and score\n",
    "        loss = criterion(z, batch[1].cpu())\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        total += 1\n",
    "        \n",
    "        # Load in confusion_matrix\n",
    "        for i in range(1):\n",
    "            \n",
    "            row = batch[1][i]\n",
    "            col = torch.argmax(z)\n",
    "            confusion_matrix[num_epochs][row][col] += 1\n",
    "     \n",
    "    num_epochs += 1\n",
    "        \n",
    "    return epoch_loss/total\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch start:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000it [00:09, 846.39it/s]\n",
      "2000it [00:00, 5454.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 9s\tTrain Loss: 0.692 | Test Loss: 0.693\n",
      "epoch start:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000it [00:09, 846.30it/s]\n",
      "2000it [00:00, 5295.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 9s\tTrain Loss: 0.691 | Test Loss: 0.693\n",
      "epoch start:  2\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):  \n",
    "    print(\"epoch start: \", epoch)  \n",
    "    start_time = time.time()\n",
    "    training_loss = train(ScoreAssigner, training_iterator, optimizer, criterion, CLIP)\n",
    "    training_losses.append(training_loss)\n",
    "    test_loss = evaluate(ScoreAssigner, test_iterator, criterion)\n",
    "    test_losses.append(test_loss)  \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss \n",
    "        torch.save(ScoreAssigner.state_dict(), 'best_model.pt')\n",
    "        \n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s', end='')\n",
    "    print(f'\\tTrain Loss: {training_loss:.3f} | Test Loss: {test_loss:.3f}')\n",
    "\n",
    "import pickle\n",
    "with open(f'results/losses_L{N_LAYERS}_D{DROPOUT}_B{BIDIRECT}.pkl', 'wb') as f:\n",
    "    pickle.dump({'training_losses': training_losses,\n",
    "                'test_losses': test_losses}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdd0dec0f50>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "x = np.arange(len(training_losses))\n",
    "plt.plot(x, training_losses, label = 'training loss')\n",
    "plt.plot(x, test_losses, label = 'test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list[10][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"p\"\n",
    "example2 = \"q\"\n",
    "example3 = \"~ p\"\n",
    "example4 = \"p & ~ p\"\n",
    "example_s1 = \"~ p => q\"\n",
    "example_s2 = test_list[100][1]\n",
    "example_s3 = \"( q ( <=> ( ( ~ ( ~ q ) ) ( & q ) ) ) )\"\n",
    "\n",
    "words1 = example1.split(\" \")\n",
    "words2 = example2.split(\" \")\n",
    "words3 = example3.split(\" \")\n",
    "words4 = example4.split(\" \")\n",
    "words5 = example_s1.split(\" \")\n",
    "words6 = example_s2.split(\" \")\n",
    "\n",
    "seq1 = []\n",
    "seq2 = []\n",
    "seq3 = []\n",
    "seq4 = []\n",
    "seq5 = []\n",
    "seq6 = []\n",
    "for word in words1:\n",
    "    seq1.append(corpora.word_index[word])\n",
    "for word in words2:\n",
    "    seq2.append(corpora.word_index[word])\n",
    "for word in words3:\n",
    "    seq3.append(corpora.word_index[word])\n",
    "for word in words4:\n",
    "    seq4.append(corpora.word_index[word])\n",
    "for word in words5:\n",
    "    seq5.append(corpora.word_index[word])\n",
    "for word in words6:\n",
    "    seq6.append(corpora.word_index[word])\n",
    "\n",
    "\n",
    "seq1 = torch.tensor([seq1]).cpu()\n",
    "seq2 = torch.tensor([seq2]).cpu()\n",
    "seq3 = torch.tensor([seq3]).cpu()\n",
    "seq4 = torch.tensor([seq4]).cpu()\n",
    "seq5 = torch.tensor([seq5]).cpu()\n",
    "seq6 = torch.tensor([seq6]).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = ScoreAssigner.forward(seq1)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example1, \"\\nprediction: \", z)\n",
    "z = ScoreAssigner.forward(seq2)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example2, \"\\nprediction: \", z)\n",
    "z = ScoreAssigner.forward(seq3)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example3, \"\\nprediction: \", z)\n",
    "z = ScoreAssigner.forward(seq4)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example4, \"\\nprediction: \", z)\n",
    "z = ScoreAssigner.forward(seq5)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s1, \"\\nprediction: \", z)\n",
    "z = ScoreAssigner.forward(seq6)\n",
    "d = torch.softmax(z,dim=-1)\n",
    "print(\"Example: \", example_s2, \"\\nprediction: \", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[798., 218.],\n",
      "        [485., 499.]])\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix[35])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
